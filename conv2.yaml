default_hparams: cifar_conv2
batch_size: 60
gpu: '7'
levels: 20
lr: 0.0002
model_name: cifar_conv2
optimizer_name: adam
replicate: 5
subcommand: lottery_branch
branch_name: property_distribution
#algorithm: erank
#weight_reg_coeff: 1
#init_lr: 0.001
#lth_path: /home/noga/open_lth_data/lottery_ef397e7945fab680facffda51c288a09/replicate_5/
#lth_data: random_color
trials: 1000
property: features_erank
#conv_layers: true
seed: 259
dataset_name: cifar10
training_steps: 40ep
pruning_fraction: 0.2
pruning_layers_to_ignore: fc.weight
pruning_strategy: sparse_global
pruning_fraction_last_fc: 0.1
pruning_conv: 0.1
apex_fp16: false
batchnorm_frozen: false
batchnorm_init: uniform
blur_factor: null
data_order_seed: null
display_output_location: false
do_not_augment: true
evaluate_only_at_end: false
gamma: null
milestone_steps: null
model_init: kaiming_normal
momentum: 0.0
nesterov_momentum: 0.0
num_workers: 3
others_frozen: false
others_frozen_exceptions: null
output_frozen: false
platform: local
pretrain: false
quiet: false
random_labels_fraction: null
rewinding_steps: null
subsample_fraction: null
transformation_seed: null
unsupervised_labels: null
warmup_steps: null
weight_decay: null
