default_hparams: cifar_conv6
batch_size: 60
gpu: '6'
levels: 10-25
lr: 0.0003
model_name: cifar100_conv6
optimizer_name: adam
replicate: 5
subcommand: lottery_branch
branch_name: cross_domain
#trial: 100000
#property: features_erank
#conv_layers: true
#seed: 259
lth_path: /home/noga/open_lth_data/lottery_fcd2078307525571decefce0d451fcc2/replicate_5/
lth_data: random_color
#algorithm: erank
#steps: 1000
#init_lr: 0.05
#weight_reg_coeff: -0.0001
#features_norm_coeff: 0.001
#seed: 512
dataset_name: cifar100
training_steps: 40ep
pruning_fraction: 0.2
pruning_layers_to_ignore: fc.weight
pruning_strategy: sparse_global
pruning_fraction_last_fc: 0.1
pruning_conv: 0.15
apex_fp16: false
batchnorm_frozen: false
batchnorm_init: uniform
blur_factor: null
data_order_seed: null
display_output_location: false
do_not_augment: true
evaluate_only_at_end: false
gamma: null
milestone_steps: null
model_init: kaiming_normal
momentum: 0.0
nesterov_momentum: 0.0
num_workers: 4
others_frozen: false
others_frozen_exceptions: null
output_frozen: false
platform: local
pretrain: false
quiet: false
random_labels_fraction: null
rewinding_steps: null
subsample_fraction: null
transformation_seed: null
unsupervised_labels: null
warmup_steps: null
weight_decay: null
